{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "날짜 : 2020/08/20\n",
    "이름 : 유효진\n",
    "내용 : LSTM imdb 텍스트 분석 실습하기\n",
    "\"\"\"\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋 로드하기\n",
    "(imdb_train_data, imdb_train_label), (imdb_test_data, imdb_test_label) = imdb.load_data(num_words=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,) (25000,)\n",
      "(25000,) (25000,)\n",
      "the as you with out themselves powerful and and their becomes and had and of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every and and movie except her was several of enough more with is now and film as you of and and unfortunately of you than him that with out themselves her get for was and of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of and and with heart had and they of here that with her serious to have does when from why what have and they is you that isn't one will very to as itself with other and in of seen over and for anyone of and br and to whether from than out themselves history he name half some br of and and was two most of mean for 1 any an and she he should is thought and but of script you not while history he heart to real at and but when from one bit then have two of script their with her and most that with wasn't to with and acting watch an for with and film want an "
     ]
    }
   ],
   "source": [
    "#데이터 확인하기\n",
    "print(imdb_train_data.shape, imdb_train_label.shape)\n",
    "print(imdb_test_data.shape, imdb_test_label.shape)\n",
    "\n",
    "# 영문을 숫자로 변환한 형태로 출력\n",
    "#imdb_train_data[0]\n",
    "\n",
    "# 긍정 1, 부정 0\n",
    "#imdb_train_label\n",
    "\n",
    "#시퀀스데이터 영어 문장으로 변환\n",
    "imdb_get_word_index = {}\n",
    "\n",
    "for word, value in imdb.get_word_index().items():\n",
    "    #print(word, '--->', value)\n",
    "    imdb_get_word_index[value] = word\n",
    "    \n",
    "#imdb_get_word_index[1]\n",
    "\n",
    "for w in imdb_train_data[0]:\n",
    "    print(imdb_get_word_index[w], end=' ')\n",
    "    \n",
    "    '''\n",
    "    데이터셋 로드 시 단어 수를 1000개로 제한해서 온전한 문장이 아님\n",
    "    가장 많이 언급된 단어들만 수집한 것\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 전 : 218\n",
      "패딩 전 : 189\n",
      "패딩 후 : 500\n",
      "패딩 후 : 500\n"
     ]
    }
   ],
   "source": [
    "#데이터 전처리(데이터를 동일한 길이로 맞추기)\n",
    "\n",
    "print('패딩 전 :', len(imdb_train_data[0]))\n",
    "print('패딩 전 :', len(imdb_train_data[1]))\n",
    "\n",
    "pad_imdb_train_data = pad_sequences(imdb_train_data, maxlen=500, padding='pre')\n",
    "pad_imdb_test_data = pad_sequences(imdb_test_data, maxlen=500, padding='pre')\n",
    "\n",
    "print('패딩 후 :', len(pad_imdb_train_data[0]))\n",
    "print('패딩 후 :', len(pad_imdb_train_data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=1000, output_dim=32))\n",
    "model.add(LSTM(32, return_sequences=True)) #순환층\n",
    "model.add(Dense(1, activation='sigmoid')) #출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 설정하기\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6934 - acc: 0.4963 - val_loss: 0.6931 - val_acc: 0.5102\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6932 - acc: 0.5015 - val_loss: 0.6932 - val_acc: 0.4931\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6932 - acc: 0.5023 - val_loss: 0.6931 - val_acc: 0.5058\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 42s 66ms/step - loss: 0.6930 - acc: 0.5047 - val_loss: 0.6931 - val_acc: 0.5072\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6933 - acc: 0.5053 - val_loss: 0.6933 - val_acc: 0.5052\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6928 - acc: 0.5063 - val_loss: 0.6932 - val_acc: 0.5097\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6919 - acc: 0.5155 - val_loss: 0.6942 - val_acc: 0.5078\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.6917 - acc: 0.5131 - val_loss: 0.6941 - val_acc: 0.5066\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 41s 65ms/step - loss: 0.6928 - acc: 0.5079 - val_loss: 0.6935 - val_acc: 0.5036\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 41s 66ms/step - loss: 0.6929 - acc: 0.5082 - val_loss: 0.6947 - val_acc: 0.4887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18d2d720bb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 학습하기\n",
    "model.fit(pad_imdb_train_data,\n",
    "          imdb_test_label,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 17s 22ms/step - loss: 0.6948 - acc: 0.4948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6948060989379883, 0.49478352069854736]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#모델 평가하기\n",
    "model.evaluate(pad_imdb_test_data, imdb_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측하기\n",
    "sample_text = ['i love this movie', 'it is waste of time']\n",
    "result = model.predict(sample_text)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
